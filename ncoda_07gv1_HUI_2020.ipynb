{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nDetVnGnoHR-"
   },
   "source": [
    "# Housing Unit Allocation with Person Record File Full Workflow\n",
    "\n",
    "## Overview\n",
    "This code works with the National Structures Inventory to run the housing unit allocation (HUA) and the person record file (PREC) workflow.\n",
    "The HUA process is generalizable to any county in the United States. The HUA process will work for any file that has locations of structures and some basic information about the buildings.\n",
    "The process is designed to work with [IN-CORE](https://incore.ncsa.illinois.edu/), a community resilience modeling environment.\n",
    "Using IN-CORE requires an account and access to the IN-CORE Dataservice.\n",
    "\n",
    "Functions are provided to obtain and clean data required for the version 2 Housing Unit Allocation. \n",
    "\n",
    "## Required Inputs\n",
    "Program requires the following inputs:\n",
    "If using the National Structures Inventory there are no required inputs.\n",
    "    \n",
    "## Output Description\n",
    "The output of this workflow is a CSV file with the housing unit inventory allocated to a building inventory using the housing unit allocation model.\n",
    "\n",
    "The output CSV is designed to be used in the Interdependent Networked Community Resilience Modeling Environment (IN-CORE).\n",
    "\n",
    "IN-CORE is an open source python package that can be used to model the resilience of a community. To download IN-CORE, see:\n",
    "\n",
    "https://incore.ncsa.illinois.edu/\n",
    "\n",
    "\n",
    "## Instructions\n",
    "Users can run the workflow by executing each block of code in the notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Program\n",
    "- program:    ncoda_07fv1_HUA_PREC_NSI\n",
    "- task:       Start with NSI building inventory, run housing unit allocation algorithm, and then run person record file algorithm\n",
    "- See github commits for description of program updates\n",
    "- Current Version: v1 - \n",
    "- 2024-02-20 - Combine code from 07c, 07d, and 07e into one notebook\n",
    "- 2024-05-22 - removed the drop down menu, did not work consistently\n",
    "- project:    Interdependent Networked Community Resilience Modeling Environment (IN-CORE), Subtask 5.2 - Social Institutions\n",
    "- funding:\t  NIST Financial Assistance Award Numbers: 70NANB15H044 and 70NANB20H008 \n",
    "- author:     Nathanael Rosenheim\n",
    "\n",
    "## Required Citations:\n",
    "Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2021). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. _Sustainable and Resilient Infrastructure_. 6(6), 385-401. https://doi.org/10.1080/23789689.2019.1681821\n",
    "\n",
    "Rosenheim, Nathanael (2021) “Detailed Household and Housing Unit Characteristics: Data and Replication Code.” _DesignSafe-CI_. \n",
    "https://doi.org/10.17603/ds2-jwf6-s535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload submodules need to use this magic command to set autoreload on\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pyncoda.ncoda_00g_community_options import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to set up the Community Dictionary\n",
    "Please review the python code in the file pyncoda/ncoda_00g_community_options.py\n",
    "\n",
    "In this file you will find a collection of data dictionaries with various ways to setup the inputs for the Housing Unit Allocation process. \n",
    "\n",
    "The basic dictionary includes the name of the community, the county FIPS code, your input building inventory file, and key variables in the building inventory file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lumberton, NC: IN-CORE Building inventory for Robeson County, NC',\n",
       " 'Galveston, TX: IN-CORE Building inventory for Galveston County, TX',\n",
       " 'Galveston, TX: NSI Building inventory for Galveston County, TX',\n",
       " 'Galveston, TX: IN-CORE Building inventory for Galveston Island, TX',\n",
       " 'Mayfield, KY: NSI Building inventory for Graves County, KY',\n",
       " 'Beaumont, TX: NSI Building inventory for Jefferson County, TX',\n",
       " 'Beaumont, TX: Safayet Building inventory for Jefferson County, TX',\n",
       " 'Pentwater, MI: NSI Building inventory for Oceana County, MI',\n",
       " 'Seaside, OR: NSI Building inventory for Clatsop County, OR',\n",
       " 'Lane County, OR: NSI Building inventory for Lane County, OR',\n",
       " 'Benton County, OR: NSI Building inventory for Benton County, OR',\n",
       " 'Southeast Texas Urban Integrated Field Lab: NSI Building inventory for Southeast Texas',\n",
       " 'Brazos County, TX: NSI Building inventory for Brazos County, TX']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a community from this list\n",
    "# if your community is not in this list, add it to the file ncoda_00g_community_options.py\n",
    "list_community_options(communities_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_id_by_name = 'Seaside, OR: NSI Building inventory for Clatsop County, OR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected community ID: Seaside_OR_NSI\n",
      "Seaside, OR is in OREGON\n",
      "Focal place: Seaside\n",
      "Seaside, OR is in Clatsop County, OR with FIPS code 41007\n",
      "Use IN-CORE: False\n"
     ]
    }
   ],
   "source": [
    "community_id, focalplace, countyname, countyfips = get_community_id_by_name(community_id_by_name)\n",
    "communities = {community_id : communities_dictionary[community_id]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd # For reading in shapefiles\n",
    "import numpy as np\n",
    "import sys # For displaying package versions\n",
    "import os # For managing directories and file paths if drive is mounted\n",
    "import scooby # Reports Python environment\n",
    "\n",
    "import contextily as cx # For adding basemap tiles to plot\n",
    "import matplotlib.pyplot as plt # For plotting and making graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open, read, and execute python program with reusable commands\n",
    "from pyncoda.ncoda_00d_cleanvarsutils import *\n",
    "from pyncoda.ncoda_04c_poptableresults import *\n",
    "from pyncoda.ncoda_07i_process_communities import process_community_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "  Date: Thu Feb 20 13:00:38 2025 Central Standard Time\n",
      "\n",
      "                OS : Windows (10 10.0.22631 SP0 Multiprocessor Free)\n",
      "            CPU(s) : 16\n",
      "           Machine : AMD64\n",
      "      Architecture : 64bit\n",
      "               RAM : 31.7 GiB\n",
      "       Environment : Jupyter\n",
      "\n",
      "  Python 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50)\n",
      "  [MSC v.1916 64 bit (AMD64)]\n",
      "\n",
      "            pandas : 2.2.2\n",
      "        ipyleaflet : Module not found\n",
      "           seaborn : 0.13.2\n",
      "        contextily : 1.6.0\n",
      "          pyincore : Module not found\n",
      "      pyincore_viz : Module not found\n",
      "             numpy : 1.26.4\n",
      "             scipy : 1.13.1\n",
      "           IPython : 8.25.0\n",
      "        matplotlib : 3.8.4\n",
      "            scooby : 0.10.0\n",
      "\n",
      "  Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303\n",
      "  for Intel(R) 64 architecture applications\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate report of Python environment\n",
    "base_packages = ['pandas','ipyleaflet','seaborn','contextily']\n",
    "incore_packages = ['pyincore','pyincore_viz']\n",
    "check_packages = base_packages + incore_packages\n",
    "print(scooby.Report(additional=check_packages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nathanael99\\\\MyProjects\\\\GitHub\\\\intersect-community-data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check working directory - good practice for relative path access\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Base Housing Unit Inventory for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open, read, and execute python program with reusable commands\n",
    "from pyncoda.ncoda_00b_directory_design import directory_design\n",
    "from pyncoda.CommunitySourceData.api_census_gov.acg_01a_BaseInventory import BaseInventory\n",
    "\n",
    "seed = 9876\n",
    "version = '2.0.0'\n",
    "version_text = 'v2-0-0'\n",
    "basevintage = 2010\n",
    "outputfolder =\"OutputData\"\n",
    "outputfolders = {}\n",
    "savefiles = True\n",
    "use_incore = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutually_exclusive_varstems_roots_dictionary_lists = {}\n",
    "new_char_dictionaries = {}\n",
    "new_char_dictionaries['family'] = {}\n",
    "new_char_dictionaries['Hispanic'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyncoda.CommunitySourceData.api_census_gov.acg_00b_hui_block2010 import *\n",
    "from pyncoda.CommunitySourceData.api_census_gov.acg_00c_hispan_block2010 import *\n",
    "\n",
    "mutually_exclusive_varstems_roots_dictionary_lists[2010] = [tenure_size_H16_varstem_roots,\n",
    "                                                    vacancy_status_H5_varstem_roots,\n",
    "                                                    group_quarters_P42_varstem_roots]\n",
    "\n",
    "new_char_dictionaries['family'][2010] = [family_byrace_P18_varstem_roots]\n",
    "new_char_dictionaries['Hispanic'][2010] = [tenure_size_H16HAI_varstem_roots,\n",
    "                                        hispan_byrace_H7_varstem_roots,\n",
    "                                        tenure_byhispan_H15_varstem_roots\n",
    "                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated for 2020\n",
    "from pyncoda.CommunitySourceData.api_census_gov.acg_00b_hui_block2020 import *\n",
    "from pyncoda.CommunitySourceData.api_census_gov.acg_00c_hispan_block2020 import *\n",
    "\n",
    "mutually_exclusive_varstems_roots_dictionary_lists[2020] = [tenure_size_H12_2020_varstem_roots,\n",
    "                                                    vacancy_status_H5_2020_varstem_roots,\n",
    "                                                    group_quarters_P18_2020_varstem_roots]\n",
    "\n",
    "new_char_dictionaries['family'][2020] = [family_byrace_P16_2020_varstem_roots]\n",
    "new_char_dictionaries['Hispanic'][2020] = [tenure_size_H12HAI_2020_varstem_roots,\n",
    "                                        hispan_byrace_H7_2020_varstem_roots,\n",
    "                                        tenure_byhispan_H11_2020_varstem_roots\n",
    "                                        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Housing Unit Inventory v2.0.0 data for Seaside, OR\n",
      "Clatsop County, OR : county FIPS Code 41007\n",
      "Generating HUI data for Clatsop County, OR\n",
      "File OutputData/Seaside_OR_NSI/03_BaseInventory/CoreHUI_41007_2020.csv Already exists - Skipping API Call.\n",
      "File OutputData/Seaside_OR_NSI/03_BaseInventory/hui_family_41007_2020.csv Already exists with new variable grafted - Skipping API Call.\n",
      "Base Housing Unit Inventory has new characteristic hispan\n",
      "Graft process will predict missing values of  hispan\n",
      "\n",
      "***************************************\n",
      "    Base Inventory has 2079 observations not set\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Predicting hispan based on ['numprec', 'ownershp', 'hispanbyH12HAI', 'byracehispan'] ['numprec', 'ownershp'] H12HAI\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Base Inventory has 2079 observations not set\n",
      "***************************************\n",
      "\n",
      "File OutputData/Seaside_OR_NSI/02_TidyCommunitySourceData/H12HAI_41007_2020.csv Already exists - Skipping API Call.\n",
      "hispanbyH12HAI\n",
      "Fill missing values with 0\n",
      "\n",
      "***************************************\n",
      "    Predicting hispan based on ['race', 'hispanbyH7'] ['race'] H7\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Base Inventory has 534 observations not set\n",
      "***************************************\n",
      "\n",
      "File OutputData/Seaside_OR_NSI/02_TidyCommunitySourceData/H7_41007_2020.csv Already exists - Skipping API Call.\n",
      "hispanbyH7\n",
      "Fill missing values with 0\n",
      "\n",
      "***************************************\n",
      "    Predicting hispan based on ['ownershp', 'hispanbyH11'] ['ownershp'] H11\n",
      "***************************************\n",
      "\n",
      "\n",
      "***************************************\n",
      "    Base Inventory has 320 observations not set\n",
      "***************************************\n",
      "\n",
      "['ownershp', 'hispanbyH11']\n",
      "\n",
      "**********************************\n",
      "Obtain data from Census API TENURE BY HISPANIC OR LATINO ORIGIN OF HOUSEHOLDER\n",
      "    Obtaining data for H11 TENURE BY HISPANIC OR LATINO ORIGIN OF HOUSEHOLDER by Race and Hispanic Not Applicable\n",
      "       Census API data from: https://api.census.gov/data/2020/dec/dhc?get=GEO_ID,H11_004N,H11_007N&in=state:41&in=county:007&for=block:*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950400' '950400' '950400' '950400' '950400' '950400' '950400' '950400'\n",
      " '950400' '950400' '950400' '950400' '950400' '950400' '950400' '950400'\n",
      " '950400' '950400' '950400' '950400' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950700' '950700' '950700' '950700' '950700'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950700'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950700'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951300' '951300' '951300' '951300' '951300'\n",
      " '951300' '951300' '951300' '951300' '951300']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1000' '1007' '1013' '1013' '1013' '1013' '1013' '1015' '1016' '1016'\n",
      " '1021' '1021' '2000' '2001' '2002' '2002' '2002' '2003' '2004' '2004'\n",
      " '2008' '2011' '3000' '3000' '3001' '3001' '3001' '3001' '3001' '3005'\n",
      " '3005' '3005' '3005' '3005' '3006' '3006' '3007' '3007' '3007' '3007'\n",
      " '3007' '3007' '3007' '3007' '3008' '3008' '1004' '1010' '1010' '1012'\n",
      " '1014' '1018' '1018' '1023' '2002' '2014' '2019' '2020' '2022' '2022'\n",
      " '2027' '2027' '3005' '3005' '3006' '3006' '3006' '3007' '3027' '3028'\n",
      " '4001' '4001' '4001' '4006' '4006' '4006' '4006' '4023' '4024' '4024'\n",
      " '4025' '4025' '1007' '1007' '1013' '1014' '1017' '1017' '1026' '1028'\n",
      " '1028' '2000' '2001' '2001' '2001' '2004' '2004' '2008' '2011' '2018'\n",
      " '2018' '3038' '3040' '3040' '3040' '3041' '3045' '3045' '3045' '3045'\n",
      " '3045' '3045' '3047' '3055' '3055' '3055' '3055' '3055' '3055' '3055'\n",
      " '1005' '1011' '1024' '1028' '1035' '1035' '1035' '1038' '1053' '2029'\n",
      " '2034' '2047' '2053' '2053' '2057' '2057' '2077' '2078' '2092' '3013'\n",
      " '1005' '1005' '1007' '1008' '1010' '1010' '1012' '1012' '1012' '1016'\n",
      " '1026' '1026' '1027' '1027' '1027' '1034' '1034' '1034' '1034' '1042'\n",
      " '1044' '1044' '2009' '2010' '2015' '2015' '2015' '2021' '2021' '2021'\n",
      " '2044' '2045' '2045' '3000' '3005' '3005' '3006' '3006' '3009' '4000'\n",
      " '4000' '4000' '4000' '4000' '4003' '4004' '4005' '4007' '4008' '4008'\n",
      " '4008' '4014' '4018' '4018' '4018' '4018' '4019' '4020' '4020' '4021'\n",
      " '4021' '4021' '4023' '4023' '4025' '4029' '1005' '1005' '1006' '1008'\n",
      " '1008' '1008' '1008' '1009' '1009' '1010' '1012' '1012' '1015' '1023'\n",
      " '1026' '1027' '1038' '1048' '1052' '1059' '1059' '1068' '1069' '1070'\n",
      " '1084' '1110' '2002' '2002' '2002' '2002' '2006' '2007' '2012' '2012'\n",
      " '2013' '3005' '3010' '3010' '3010' '3011' '3011' '3011' '3011' '3011'\n",
      " '3012' '1002' '1005' '1009' '1009' '1013' '1013' '1013' '1013' '1013'\n",
      " '1013' '1013' '1013' '1013' '2021' '2021' '2021' '2021' '2022' '2031'\n",
      " '2031' '2031' '2032' '2033' '2048' '2049' '2049' '2050' '2059' '1000'\n",
      " '1000' '1000' '1000' '1001' '1001' '1001' '1001' '1001' '1002' '1011'\n",
      " '2006' '2006' '2007' '2008' '2010' '2010' '2010' '2010' '2010' '2010'\n",
      " '2010' '2010' '2010' '2010' '2010' '2015' '2020' '2021' '2021' '2033'\n",
      " '2034' '2035' '2037' '2038' '2038' '2040' '2049' '3003' '3003' '3004'\n",
      " '3004' '3007' '3007' '3008' '3009' '3010' '3011' '3011' '3018' '3033'\n",
      " '3036' '3036' '3036' '3036' '3038' '3044' '3044' '3045' '3046' '4000'\n",
      " '4000' '4000' '4022' '4022' '4029' '4029' '5000' '5000' '5000' '5000'\n",
      " '5002' '5002' '5002' '5002' '5003' '5003' '5003' '5003' '5004' '5014'\n",
      " '5018' '5019' '5023' '5023' '5023' '5028' '5033' '5034' '5035' '5035'\n",
      " '1009' '1009' '1009' '1009' '1009' '1009' '1009' '1009' '1020' '1023'\n",
      " '1023' '1023' '1023' '1025' '1029' '1029' '1029' '1030' '1036' '1043'\n",
      " '1043' '1067' '1080' '1087' '1105' '2004' '2005' '2016' '2028' '2028'\n",
      " '2028' '2028' '2030' '2031' '2031' '2031' '2031' '2034' '2040' '2044'\n",
      " '2104' '2104' '2113' '2114' '3003' '3014' '3029' '3050' '3052' '3065'\n",
      " '3065' '3065' '3065' '3081' '3087' '3087' '4007' '4008' '4008' '4011'\n",
      " '4014' '4024' '4024' '4024' '4033' '4040' '4040' '4043' '1024' '1038'\n",
      " '1038' '1056' '1056' '1056' '1061' '1061' '1066' '1066' '1081' '1081'\n",
      " '1081' '1081' '2022' '2023' '2023' '2029' '3015' '3075' '3075' '3075'\n",
      " '3075' '3075' '3081' '3081' '3141' '3157' '3269' '1005' '1006' '1009'\n",
      " '1034' '1049' '1067' '1067' '1074' '1074' '2019']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41' '41'\n",
      " '41' '41' '41' '41']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007' '007'\n",
      " '007' '007']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950100' '950100' '950100' '950100' '950100' '950100'\n",
      " '950100' '950100' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950200'\n",
      " '950200' '950200' '950200' '950200' '950200' '950200' '950200' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950300' '950300' '950300' '950300' '950300' '950300' '950300' '950300'\n",
      " '950400' '950400' '950400' '950400' '950400' '950400' '950400' '950400'\n",
      " '950400' '950400' '950400' '950400' '950400' '950400' '950400' '950400'\n",
      " '950400' '950400' '950400' '950400' '950400' '950400' '950400' '950400'\n",
      " '950400' '950400' '950400' '950400' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950500' '950500'\n",
      " '950500' '950500' '950500' '950500' '950500' '950500' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950600' '950600' '950600' '950600' '950600' '950600' '950600' '950600'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950700'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950700'\n",
      " '950700' '950700' '950700' '950700' '950700' '950700' '950700' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '950900' '950900' '950900' '950900' '950900' '950900'\n",
      " '950900' '950900' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951100' '951100' '951100' '951100' '951100' '951100'\n",
      " '951100' '951100' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951200' '951200' '951200' '951200'\n",
      " '951200' '951200' '951200' '951200' '951300' '951300' '951300' '951300'\n",
      " '951300' '951300' '951300' '951300' '951300' '951300' '951300' '951300'\n",
      " '951300' '951300' '951300' '951300' '951300' '951300']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n",
      "c:\\Users\\nathanael99\\MyProjects\\GitHub\\intersect-community-data\\pyncoda\\CommunitySourceData\\api_census_gov\\acg_01a_BaseInventory.py:418: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['1000' '1007' '1007' '1013' '1013' '1013' '1015' '1015' '1016' '1016'\n",
      " '1021' '1021' '2000' '2000' '2000' '2001' '2001' '2002' '2002' '2003'\n",
      " '2004' '2008' '2008' '2011' '3000' '3000' '3001' '3001' '3005' '3005'\n",
      " '3006' '3006' '3006' '3006' '3007' '3007' '3007' '3007' '3008' '3008'\n",
      " '3008' '3009' '1004' '1010' '1010' '1012' '1014' '1017' '1018' '1021'\n",
      " '1023' '1025' '1028' '2002' '2002' '2004' '2014' '2019' '2019' '2020'\n",
      " '2020' '2022' '2025' '2027' '2027' '3005' '3005' '3005' '3006' '3006'\n",
      " '3007' '3010' '3013' '3027' '3028' '3028' '4001' '4001' '4006' '4006'\n",
      " '4006' '4023' '4023' '4024' '4025' '4025' '4029' '1007' '1007' '1007'\n",
      " '1013' '1014' '1017' '1017' '1017' '1026' '1028' '1028' '2000' '2001'\n",
      " '2001' '2004' '2008' '2011' '2018' '2018' '2018' '3038' '3040' '3041'\n",
      " '3045' '3045' '3045' '3045' '3047' '3055' '3055' '3055' '3055' '3056'\n",
      " '1005' '1011' '1023' '1024' '1024' '1028' '1035' '1035' '1035' '1038'\n",
      " '1053' '2029' '2034' '2034' '2040' '2047' '2053' '2053' '2053' '2057'\n",
      " '2057' '2077' '2078' '2078' '2092' '3013' '3013' '3019' '1005' '1005'\n",
      " '1007' '1008' '1010' '1010' '1010' '1012' '1016' '1026' '1027' '1034'\n",
      " '1034' '1034' '1042' '1044' '1044' '2009' '2009' '2010' '2013' '2015'\n",
      " '2015' '2021' '2025' '2026' '2027' '2044' '2045' '2045' '2045' '3000'\n",
      " '3005' '3005' '3005' '3006' '3006' '3009' '4000' '4000' '4000' '4003'\n",
      " '4004' '4004' '4005' '4007' '4008' '4008' '4008' '4014' '4014' '4015'\n",
      " '4018' '4018' '4019' '4019' '4020' '4021' '4021' '4023' '4023' '4024'\n",
      " '4025' '4025' '4026' '4029' '1005' '1005' '1006' '1008' '1008' '1008'\n",
      " '1009' '1010' '1011' '1012' '1012' '1015' '1015' '1023' '1026' '1026'\n",
      " '1027' '1038' '1048' '1048' '1049' '1052' '1059' '1059' '1068' '1069'\n",
      " '1070' '1083' '1084' '1107' '1110' '1110' '2002' '2002' '2002' '2002'\n",
      " '2003' '2006' '2007' '2012' '2013' '3005' '3006' '3010' '3010' '3011'\n",
      " '3011' '3011' '3012' '3012' '1002' '1005' '1005' '1009' '1009' '1009'\n",
      " '1013' '1013' '1013' '2021' '2021' '2021' '2021' '2022' '2031' '2031'\n",
      " '2032' '2033' '2048' '2049' '2049' '2050' '2059' '1000' '1000' '1001'\n",
      " '1001' '1001' '1001' '1002' '1011' '1011' '1026' '2006' '2006' '2006'\n",
      " '2007' '2008' '2008' '2010' '2010' '2010' '2015' '2015' '2020' '2021'\n",
      " '2033' '2034' '2035' '2035' '2037' '2038' '2038' '2038' '2040' '2049'\n",
      " '3003' '3003' '3004' '3004' '3004' '3007' '3007' '3008' '3009' '3010'\n",
      " '3010' '3011' '3011' '3013' '3018' '3033' '3035' '3036' '3036' '3036'\n",
      " '3038' '3039' '3044' '3044' '3045' '3046' '4000' '4000' '4000' '4016'\n",
      " '4022' '4029' '4029' '5000' '5000' '5000' '5000' '5002' '5002' '5003'\n",
      " '5003' '5003' '5003' '5004' '5006' '5014' '5018' '5018' '5019' '5023'\n",
      " '5023' '5026' '5028' '5030' '5033' '5034' '5034' '5035' '1009' '1009'\n",
      " '1009' '1009' '1009' '1011' '1020' '1020' '1023' '1023' '1023' '1025'\n",
      " '1029' '1029' '1030' '1036' '1039' '1040' '1043' '1043' '1067' '1080'\n",
      " '1087' '1105' '2004' '2005' '2009' '2016' '2028' '2028' '2028' '2030'\n",
      " '2031' '2031' '2034' '2040' '2044' '2078' '2104' '2113' '2114' '3003'\n",
      " '3003' '3006' '3014' '3015' '3029' '3050' '3052' '3065' '3065' '3065'\n",
      " '3081' '3087' '4007' '4008' '4011' '4014' '4024' '4024' '4033' '4040'\n",
      " '4040' '4043' '1024' '1038' '1038' '1038' '1041' '1055' '1056' '1056'\n",
      " '1061' '1063' '1066' '1066' '1081' '1081' '1081' '2008' '2022' '2022'\n",
      " '2023' '2023' '2023' '2029' '2071' '3015' '3033' '3075' '3075' '3075'\n",
      " '3081' '3141' '3157' '3157' '3269' '3279' '1004' '1005' '1006' '1009'\n",
      " '1009' '1034' '1049' '1067' '1074' '1074' '1077' '1080' '1081' '2005'\n",
      " '2013' '2015' '2019' '2019']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,geo_level] =  df[geo_level].apply(lambda x: str(x).zfill(len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************\n",
      "Reshape dataframe to convert unit of analysis\n",
      "   For mutually exclusive dataframe for: TENURE BY HISPANIC OR LATINO ORIGIN OF HOUSEHOLDER\n",
      "       Unit of analysis converted from 2173 block s, to 352 household\n",
      "hispanbyH11\n",
      "Fill missing values with 0\n",
      "['Block2020str', 'numprec', 'ownershp']\n",
      "Updating hispanbyH12HAI_counter  based on total probability and ['Block2020str', 'numprec', 'ownershp']\n",
      "['Block2020str', 'race']\n",
      "Updating hispanbyH7_counter  based on total probability and ['Block2020str', 'race']\n",
      "['Block2020str', 'ownershp']\n",
      "Updating hispanbyH11_counter  based on total probability and ['Block2020str', 'ownershp']\n",
      "Merge vars for hispanbyH12HAI_counter = ['Block2020str', 'numprec', 'ownershp']\n",
      "Updating flags based on hucount_hispanbyH12HAIupdated\n",
      "Merge vars for hispanbyH7_counter = ['Block2020str', 'race']\n",
      "Updating flags based on hucount_hispanbyH7updated\n",
      "Merge vars for hispanbyH11_counter = ['Block2020str', 'ownershp']\n",
      "Updating flags based on hucount_hispanbyH11updated\n",
      "Length of Set1 split dataframe 21032\n",
      "Length of Not Set split dataframe 137\n",
      "Length of hispanbyH12HAI split dataframe 1545\n",
      "Length of hispanbyH7 split dataframe 214\n",
      "Length of hispanbyH11 split dataframe 8\n",
      "Length of hispanbyH12HAI_counter split dataframe 151\n",
      "Length of hispanbyH7_counter split dataframe 4\n",
      "Length of hispanbyH11_counter split dataframe 20\n",
      "\n",
      "\n",
      "Shape of dataframe after total sum: (23111, 43)\n",
      "['prob_hispanbyH12HAI', 'prob_hispanbyH7', 'prob_hispanbyH11']\n",
      "hispanbyH12HAI\n",
      "hispanbyH7\n",
      "hispanbyH11\n"
     ]
    }
   ],
   "source": [
    "vintage = 2020\n",
    "for community in communities.keys():\n",
    "\n",
    "    # Create empty container to store outputs for in-core\n",
    "    # Will use these to combine multiple counties\n",
    "    hui_incore_county_df = {}\n",
    "    title = \"Housing Unit Inventory v2.0.0 data for \"+communities[community]['community_name']\n",
    "    print(\"Generating\",title)\n",
    "    output_filename = f'hui_{version_text}_{community}_{basevintage}_rs{seed}'\n",
    "\n",
    "    county_list = ''\n",
    "\n",
    "    # set output folder\n",
    "    outputfolders = directory_design(\n",
    "                        state_county_name = community,\n",
    "                        outputfolder = outputfolder)\n",
    "\n",
    "    # community dictionary\n",
    "    community_dict = communities[community]\n",
    "    use_incore = community_dict['building_inventory']['use_incore']\n",
    "\n",
    "\n",
    "    # Workflow for generating HUI data for IN-CORE\n",
    "    for county in communities[community]['counties'].keys():\n",
    "        state_county = communities[community]['counties'][county]['FIPS Code']\n",
    "        state_county_name  = communities[community]['counties'][county]['Name']\n",
    "        print(state_county_name,': county FIPS Code',state_county)\n",
    "        county_list = county_list + state_county_name+': county FIPS Code '+state_county\n",
    "\n",
    "        print(\"Generating HUI data for\",state_county_name)\n",
    "\n",
    "        # create output folders for hui data generation\n",
    "        outputfolders = directory_design(state_county_name = community,\n",
    "                                            outputfolder = outputfolder)\n",
    "                          \n",
    "        # Generate base housing unit inventory\n",
    "        block_df = {}\n",
    "        block_df['core'] = BaseInventory.get_apidata(state_county = state_county, \n",
    "                                                    geo_level = 'Block',\n",
    "                                                    vintage = str(vintage),\n",
    "                                                    mutually_exclusive_varstems_roots_dictionaries =\n",
    "                                                                        mutually_exclusive_varstems_roots_dictionary_lists[vintage],\n",
    "                                                    outputfolders = outputfolders,\n",
    "                                                    outputfile = \"CoreHUI\")\n",
    "        \n",
    "        block_df['family'] = BaseInventory.graft_on_new_char(base_inventory= block_df['core'],\n",
    "                                                            state_county = state_county,\n",
    "                                                            new_char = 'family',\n",
    "                                                            new_char_dictionaries = new_char_dictionaries['family'][vintage],\n",
    "                                                            basevintage = str(vintage), \n",
    "                                                            basegeolevel = 'Block',\n",
    "                                                            outputfile = \"hui\",\n",
    "                                                            outputfolders = outputfolders)\n",
    "\n",
    "       \n",
    "        block_df['hispan'] = BaseInventory.graft_on_new_char(base_inventory= block_df['family'],\n",
    "                                                        state_county = state_county,\n",
    "                                                        new_char = 'hispan',\n",
    "                                                        new_char_dictionaries = new_char_dictionaries['Hispanic'][vintage],\n",
    "                                                        basevintage = str(vintage), \n",
    "                                                        basegeolevel = 'Block',\n",
    "                                                        outputfile = \"hui\",\n",
    "                                                        outputfolders = outputfolders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huid</th>\n",
       "      <th>Block2020</th>\n",
       "      <th>Block2020str</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>family</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>ageP18</th>\n",
       "      <th>sex</th>\n",
       "      <th>hu_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B410079501001007H001</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B410079501001007H002</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B410079501001007H003</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B410079501001007H004</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B410079501001012H001</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   huid        Block2020      Block2020str  numprec  ownershp  \\\n",
       "0  B410079501001007H001  410079501001007  B410079501001007      1.0       1.0   \n",
       "1  B410079501001007H002  410079501001007  B410079501001007      3.0       1.0   \n",
       "2  B410079501001007H003  410079501001007  B410079501001007      4.0       1.0   \n",
       "3  B410079501001007H004  410079501001007  B410079501001007      4.0       1.0   \n",
       "4  B410079501001012H001  410079501001012  B410079501001012      1.0       1.0   \n",
       "\n",
       "   family  race  hispan  vacancy  gqtype  ageP18  sex  hu_counter  \n",
       "0     0.0   1.0     0.0      NaN     NaN     NaN  NaN           1  \n",
       "1  -999.0   1.0     0.0      NaN     NaN     NaN  NaN           2  \n",
       "2  -999.0   1.0     0.0      NaN     NaN     NaN  NaN           3  \n",
       "3  -999.0   1.0     0.0      NaN     NaN     NaN  NaN           4  \n",
       "4     0.0   1.0     0.0      NaN     NaN     NaN  NaN           1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df['core'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huid</th>\n",
       "      <th>Block2020</th>\n",
       "      <th>Block2020str</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>family</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>...</th>\n",
       "      <th>hu_counter</th>\n",
       "      <th>family_flag</th>\n",
       "      <th>family_flagset</th>\n",
       "      <th>totalprob_family</th>\n",
       "      <th>familybyP16</th>\n",
       "      <th>hucount_familybyP16</th>\n",
       "      <th>sumby_familybyP16</th>\n",
       "      <th>prob_familybyP16</th>\n",
       "      <th>familybyP16_counter</th>\n",
       "      <th>hucount_familybyP16updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B410079501001007H001</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>family set to 0 by core hui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B410079501001012H001</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>family set to 0 by core hui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B410079501001012H002</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>family set to 0 by core hui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B410079501001012H003</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>family set to 0 by core hui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B410079501001012H004</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>family set to 0 by core hui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   huid        Block2020      Block2020str  numprec  ownershp  \\\n",
       "0  B410079501001007H001  410079501001007  B410079501001007      1.0       1.0   \n",
       "1  B410079501001012H001  410079501001012  B410079501001012      1.0       1.0   \n",
       "2  B410079501001012H002  410079501001012  B410079501001012      1.0       1.0   \n",
       "3  B410079501001012H003  410079501001012  B410079501001012      1.0       1.0   \n",
       "4  B410079501001012H004  410079501001012  B410079501001012      1.0       1.0   \n",
       "\n",
       "   family  race  hispan  vacancy  gqtype  ...  hu_counter  \\\n",
       "0     0.0   1.0     0.0      NaN     NaN  ...         1.0   \n",
       "1     0.0   1.0     0.0      NaN     NaN  ...         1.0   \n",
       "2     0.0   1.0     0.0      NaN     NaN  ...         2.0   \n",
       "3     0.0   1.0     0.0      NaN     NaN  ...         3.0   \n",
       "4     0.0   1.0     0.0      NaN     NaN  ...         4.0   \n",
       "\n",
       "                   family_flag  family_flagset totalprob_family  familybyP16  \\\n",
       "0  family set to 0 by core hui             1.0              0.0          NaN   \n",
       "1  family set to 0 by core hui             1.0              0.0          NaN   \n",
       "2  family set to 0 by core hui             1.0              0.0          NaN   \n",
       "3  family set to 0 by core hui             1.0              0.0          NaN   \n",
       "4  family set to 0 by core hui             1.0              0.0          NaN   \n",
       "\n",
       "   hucount_familybyP16  sumby_familybyP16  prob_familybyP16  \\\n",
       "0                  NaN                NaN               NaN   \n",
       "1                  NaN                NaN               NaN   \n",
       "2                  NaN                NaN               NaN   \n",
       "3                  NaN                NaN               NaN   \n",
       "4                  NaN                NaN               NaN   \n",
       "\n",
       "   familybyP16_counter  hucount_familybyP16updated  \n",
       "0                  NaN                         NaN  \n",
       "1                  NaN                         NaN  \n",
       "2                  NaN                         NaN  \n",
       "3                  NaN                         NaN  \n",
       "4                  NaN                         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df['family'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huid</th>\n",
       "      <th>Block2020</th>\n",
       "      <th>Block2020str</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>family</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>...</th>\n",
       "      <th>hispanbyH11</th>\n",
       "      <th>hucount_hispanbyH11</th>\n",
       "      <th>sumby_hispanbyH11</th>\n",
       "      <th>prob_hispanbyH11</th>\n",
       "      <th>hispanbyH12HAI_counter</th>\n",
       "      <th>hispanbyH7_counter</th>\n",
       "      <th>hispanbyH11_counter</th>\n",
       "      <th>hucount_hispanbyH12HAIupdated</th>\n",
       "      <th>hucount_hispanbyH7updated</th>\n",
       "      <th>hucount_hispanbyH11updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B410079501001007H001</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B410079501001012H001</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B410079501001012H002</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B410079501001012H003</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B410079501001012H004</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   huid        Block2020      Block2020str  numprec  ownershp  \\\n",
       "0  B410079501001007H001  410079501001007  B410079501001007      1.0       1.0   \n",
       "1  B410079501001012H001  410079501001012  B410079501001012      1.0       1.0   \n",
       "2  B410079501001012H002  410079501001012  B410079501001012      1.0       1.0   \n",
       "3  B410079501001012H003  410079501001012  B410079501001012      1.0       1.0   \n",
       "4  B410079501001012H004  410079501001012  B410079501001012      1.0       1.0   \n",
       "\n",
       "   family  race  hispan  vacancy  gqtype  ...  hispanbyH11  \\\n",
       "0     0.0   1.0     0.0      NaN     NaN  ...          NaN   \n",
       "1     0.0   1.0     0.0      NaN     NaN  ...          NaN   \n",
       "2     0.0   1.0     0.0      NaN     NaN  ...          NaN   \n",
       "3     0.0   1.0     0.0      NaN     NaN  ...          NaN   \n",
       "4     0.0   1.0     0.0      NaN     NaN  ...          NaN   \n",
       "\n",
       "   hucount_hispanbyH11  sumby_hispanbyH11 prob_hispanbyH11  \\\n",
       "0                  NaN                NaN              NaN   \n",
       "1                  NaN                NaN              NaN   \n",
       "2                  NaN                NaN              NaN   \n",
       "3                  NaN                NaN              NaN   \n",
       "4                  NaN                NaN              NaN   \n",
       "\n",
       "   hispanbyH12HAI_counter  hispanbyH7_counter  hispanbyH11_counter  \\\n",
       "0                     NaN                 NaN                  NaN   \n",
       "1                     NaN                 NaN                  NaN   \n",
       "2                     NaN                 NaN                  NaN   \n",
       "3                     NaN                 NaN                  NaN   \n",
       "4                     NaN                 NaN                  NaN   \n",
       "\n",
       "   hucount_hispanbyH12HAIupdated  hucount_hispanbyH7updated  \\\n",
       "0                            NaN                        NaN   \n",
       "1                            NaN                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "\n",
       "   hucount_hispanbyH11updated  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df['hispan'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyncoda.ncoda_04c_poptableresults import *\n",
    "# add race ethnicity to data frame for better map legends\n",
    "hui_race_df = PopResultsTable.add_race_ethnicity_to_pop_df(block_df['hispan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huid</th>\n",
       "      <th>Block2020</th>\n",
       "      <th>Block2020str</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>family</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>...</th>\n",
       "      <th>hucount_hispanbyH11</th>\n",
       "      <th>sumby_hispanbyH11</th>\n",
       "      <th>prob_hispanbyH11</th>\n",
       "      <th>hispanbyH12HAI_counter</th>\n",
       "      <th>hispanbyH7_counter</th>\n",
       "      <th>hispanbyH11_counter</th>\n",
       "      <th>hucount_hispanbyH12HAIupdated</th>\n",
       "      <th>hucount_hispanbyH7updated</th>\n",
       "      <th>hucount_hispanbyH11updated</th>\n",
       "      <th>Race Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B410079501001007H001</td>\n",
       "      <td>410079501001007</td>\n",
       "      <td>B410079501001007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B410079501001012H001</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B410079501001012H002</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B410079501001012H003</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B410079501001012H004</td>\n",
       "      <td>410079501001012</td>\n",
       "      <td>B410079501001012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   huid        Block2020      Block2020str  numprec  ownershp  \\\n",
       "0  B410079501001007H001  410079501001007  B410079501001007      1.0       1.0   \n",
       "1  B410079501001012H001  410079501001012  B410079501001012      1.0       1.0   \n",
       "2  B410079501001012H002  410079501001012  B410079501001012      1.0       1.0   \n",
       "3  B410079501001012H003  410079501001012  B410079501001012      1.0       1.0   \n",
       "4  B410079501001012H004  410079501001012  B410079501001012      1.0       1.0   \n",
       "\n",
       "   family  race  hispan  vacancy  gqtype  ...  hucount_hispanbyH11  \\\n",
       "0     0.0   1.0     0.0      NaN     0.0  ...                  NaN   \n",
       "1     0.0   1.0     0.0      NaN     0.0  ...                  NaN   \n",
       "2     0.0   1.0     0.0      NaN     0.0  ...                  NaN   \n",
       "3     0.0   1.0     0.0      NaN     0.0  ...                  NaN   \n",
       "4     0.0   1.0     0.0      NaN     0.0  ...                  NaN   \n",
       "\n",
       "   sumby_hispanbyH11  prob_hispanbyH11 hispanbyH12HAI_counter  \\\n",
       "0                NaN               NaN                    NaN   \n",
       "1                NaN               NaN                    NaN   \n",
       "2                NaN               NaN                    NaN   \n",
       "3                NaN               NaN                    NaN   \n",
       "4                NaN               NaN                    NaN   \n",
       "\n",
       "   hispanbyH7_counter  hispanbyH11_counter  hucount_hispanbyH12HAIupdated  \\\n",
       "0                 NaN                  NaN                            NaN   \n",
       "1                 NaN                  NaN                            NaN   \n",
       "2                 NaN                  NaN                            NaN   \n",
       "3                 NaN                  NaN                            NaN   \n",
       "4                 NaN                  NaN                            NaN   \n",
       "\n",
       "   hucount_hispanbyH7updated  hucount_hispanbyH11updated  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                        NaN                         NaN   \n",
       "3                        NaN                         NaN   \n",
       "4                        NaN                         NaN   \n",
       "\n",
       "                Race Ethnicity  \n",
       "0  1 White alone, Not Hispanic  \n",
       "1  1 White alone, Not Hispanic  \n",
       "2  1 White alone, Not Hispanic  \n",
       "3  1 White alone, Not Hispanic  \n",
       "4  1 White alone, Not Hispanic  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_race_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaside, OR Seaside Clatsop County, OR 41007\n"
     ]
    }
   ],
   "source": [
    "where = communities[community_id]['community_name']\n",
    "print(where, focalplace, countyname, countyfips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f33a4 caption {\n",
       "  text-align: center;\n",
       "  caption-side: top;\n",
       "  font-size: 150%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f33a4\">\n",
       "  <caption>Table. Total Population by Households by Race, Ethnicity, Clatsop County, OR, 2020.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Tenure Status</th>\n",
       "      <th id=\"T_f33a4_level0_col0\" class=\"col_heading level0 col0\" >1 Owner Occupied (%)</th>\n",
       "      <th id=\"T_f33a4_level0_col1\" class=\"col_heading level0 col1\" >2 Renter Occupied (%)</th>\n",
       "      <th id=\"T_f33a4_level0_col2\" class=\"col_heading level0 col2\" >Total Population by Households (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Race Ethnicity</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row0\" class=\"row_heading level0 row0\" >1 White alone, Not Hispanic</th>\n",
       "      <td id=\"T_f33a4_row0_col0\" class=\"data row0 col0\" >22,446\t (87.5%)</td>\n",
       "      <td id=\"T_f33a4_row0_col1\" class=\"data row0 col1\" >11,421\t (76.6%)</td>\n",
       "      <td id=\"T_f33a4_row0_col2\" class=\"data row0 col2\" >33,867\t (83.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row1\" class=\"row_heading level0 row1\" >2 Black alone, Not Hispanic</th>\n",
       "      <td id=\"T_f33a4_row1_col0\" class=\"data row1 col0\" >76\t (0.3%)</td>\n",
       "      <td id=\"T_f33a4_row1_col1\" class=\"data row1 col1\" >135\t (0.9%)</td>\n",
       "      <td id=\"T_f33a4_row1_col2\" class=\"data row1 col2\" >211\t (0.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row2\" class=\"row_heading level0 row2\" >3 American Indian and Alaska Native alone, Not Hispanic</th>\n",
       "      <td id=\"T_f33a4_row2_col0\" class=\"data row2 col0\" >177\t (0.7%)</td>\n",
       "      <td id=\"T_f33a4_row2_col1\" class=\"data row2 col1\" >133\t (0.9%)</td>\n",
       "      <td id=\"T_f33a4_row2_col2\" class=\"data row2 col2\" >310\t (0.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row3\" class=\"row_heading level0 row3\" >4 Asian alone, Not Hispanic</th>\n",
       "      <td id=\"T_f33a4_row3_col0\" class=\"data row3 col0\" >357\t (1.4%)</td>\n",
       "      <td id=\"T_f33a4_row3_col1\" class=\"data row3 col1\" >165\t (1.1%)</td>\n",
       "      <td id=\"T_f33a4_row3_col2\" class=\"data row3 col2\" >522\t (1.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row4\" class=\"row_heading level0 row4\" >5 Other Race, Not Hispanic</th>\n",
       "      <td id=\"T_f33a4_row4_col0\" class=\"data row4 col0\" >1,356\t (5.3%)</td>\n",
       "      <td id=\"T_f33a4_row4_col1\" class=\"data row4 col1\" >965\t (6.5%)</td>\n",
       "      <td id=\"T_f33a4_row4_col2\" class=\"data row4 col2\" >2,321\t (5.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row5\" class=\"row_heading level0 row5\" >6 Any Race, Hispanic</th>\n",
       "      <td id=\"T_f33a4_row5_col0\" class=\"data row5 col0\" >1,252\t (4.9%)</td>\n",
       "      <td id=\"T_f33a4_row5_col1\" class=\"data row5 col1\" >2,085\t (14.0%)</td>\n",
       "      <td id=\"T_f33a4_row5_col2\" class=\"data row5 col2\" >3,337\t (8.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33a4_level0_row6\" class=\"row_heading level0 row6\" >Total</th>\n",
       "      <td id=\"T_f33a4_row6_col0\" class=\"data row6 col0\" >25,664\t (100.0%)</td>\n",
       "      <td id=\"T_f33a4_row6_col1\" class=\"data row6 col1\" >14,904\t (100.0%)</td>\n",
       "      <td id=\"T_f33a4_row6_col2\" class=\"data row6 col2\" >40,568\t (100.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17d0f36bb80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PopResultsTable.pop_results_table(\n",
    "                  input_df = hui_race_df, \n",
    "                  who = \"Total Population by Households\", \n",
    "                  what = \"by Race, Ethnicity\",\n",
    "                  where = countyname,\n",
    "                  when = \"2020\",\n",
    "                  row_index = \"Race Ethnicity\",\n",
    "                  col_index = 'Tenure Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_575c6 caption {\n",
       "  text-align: center;\n",
       "  caption-side: top;\n",
       "  font-size: 150%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_575c6\">\n",
       "  <caption>Table. Total Population by Households by Group Quarters Type, Clatsop County, OR, 2020.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >All</th>\n",
       "      <th id=\"T_575c6_level0_col0\" class=\"col_heading level0 col0\" >All (%)</th>\n",
       "      <th id=\"T_575c6_level0_col1\" class=\"col_heading level0 col1\" >Total Population by Households (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Group Quarters Type</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_575c6_level0_row0\" class=\"row_heading level0 row0\" >0. NA (non-group quarters)</th>\n",
       "      <td id=\"T_575c6_row0_col0\" class=\"data row0 col0\" >37,231\t (91.8%)</td>\n",
       "      <td id=\"T_575c6_row0_col1\" class=\"data row0 col1\" >37,231\t (91.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_575c6_level0_row1\" class=\"row_heading level0 row1\" >1 Correctional facilities for adults</th>\n",
       "      <td id=\"T_575c6_row1_col0\" class=\"data row1 col0\" >3,337\t (8.2%)</td>\n",
       "      <td id=\"T_575c6_row1_col1\" class=\"data row1 col1\" >3,337\t (8.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_575c6_level0_row2\" class=\"row_heading level0 row2\" >Total</th>\n",
       "      <td id=\"T_575c6_row2_col0\" class=\"data row2 col0\" >40,568\t (100.0%)</td>\n",
       "      <td id=\"T_575c6_row2_col1\" class=\"data row2 col1\" >40,568\t (100.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17d134a3280>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_race_df['All'] = 'All'\n",
    "\n",
    "PopResultsTable.pop_results_table(\n",
    "                  input_df = hui_race_df, \n",
    "                  who = \"Total Population by Households\", \n",
    "                  what = \"by Group Quarters Type\",\n",
    "                  where = countyname,\n",
    "                  when = \"2020\",\n",
    "                  row_index = 'Group Quarters Type',\n",
    "                  col_index = 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>huid</th>\n",
       "      <th>Block2020</th>\n",
       "      <th>Block2020str</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>family</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>ageP18</th>\n",
       "      <th>sex</th>\n",
       "      <th>hu_counter</th>\n",
       "      <th>Race Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>B410079502001025H001</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>B410079502001025H002</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>B410079502001025H003</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>B410079502001025H004</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>B410079502001025H005</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1 White alone, Not Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15229</th>\n",
       "      <td>B410079502001025H098</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>6 Any Race, Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23017</th>\n",
       "      <td>B410079502001025H099</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23018</th>\n",
       "      <td>B410079502001025H100</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23019</th>\n",
       "      <td>B410079502001025H101</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23020</th>\n",
       "      <td>B410079502001025H102</td>\n",
       "      <td>410079502001025</td>\n",
       "      <td>B410079502001025</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       huid        Block2020      Block2020str  numprec  \\\n",
       "1726   B410079502001025H001  410079502001025  B410079502001025      2.0   \n",
       "1727   B410079502001025H002  410079502001025  B410079502001025      2.0   \n",
       "1728   B410079502001025H003  410079502001025  B410079502001025      4.0   \n",
       "1729   B410079502001025H004  410079502001025  B410079502001025      6.0   \n",
       "1730   B410079502001025H005  410079502001025  B410079502001025      1.0   \n",
       "...                     ...              ...               ...      ...   \n",
       "15229  B410079502001025H098  410079502001025  B410079502001025      2.0   \n",
       "23017  B410079502001025H099  410079502001025  B410079502001025      4.0   \n",
       "23018  B410079502001025H100  410079502001025  B410079502001025      5.0   \n",
       "23019  B410079502001025H101  410079502001025  B410079502001025      7.0   \n",
       "23020  B410079502001025H102  410079502001025  B410079502001025      5.0   \n",
       "\n",
       "       ownershp  family  race  hispan  vacancy  gqtype  ageP18  sex  \\\n",
       "1726        1.0  -999.0   1.0     0.0      NaN     0.0     NaN  NaN   \n",
       "1727        1.0  -999.0   1.0     0.0      NaN     0.0     NaN  NaN   \n",
       "1728        1.0  -999.0   1.0     0.0      NaN     0.0     NaN  NaN   \n",
       "1729        1.0  -999.0   1.0     0.0      NaN     0.0     NaN  NaN   \n",
       "1730        2.0     0.0   1.0     0.0      NaN     0.0     NaN  NaN   \n",
       "...         ...     ...   ...     ...      ...     ...     ...  ...   \n",
       "15229       2.0  -999.0   1.0     1.0      NaN     1.0     NaN  NaN   \n",
       "23017       NaN     NaN   NaN     NaN      NaN     NaN     2.0  1.0   \n",
       "23018       NaN     NaN   NaN     NaN      NaN     NaN     3.0  1.0   \n",
       "23019       NaN     NaN   NaN     NaN      NaN     NaN     2.0  2.0   \n",
       "23020       NaN     NaN   NaN     NaN      NaN     NaN     3.0  2.0   \n",
       "\n",
       "       hu_counter               Race Ethnicity  \n",
       "1726            1  1 White alone, Not Hispanic  \n",
       "1727            2  1 White alone, Not Hispanic  \n",
       "1728            3  1 White alone, Not Hispanic  \n",
       "1729            4  1 White alone, Not Hispanic  \n",
       "1730            5  1 White alone, Not Hispanic  \n",
       "...           ...                          ...  \n",
       "15229          98         6 Any Race, Hispanic  \n",
       "23017          99                          NaN  \n",
       "23018         100                          NaN  \n",
       "23019         101                          NaN  \n",
       "23020         102                          NaN  \n",
       "\n",
       "[102 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list if HUID = B410079502001025H099\n",
    "block_df['core'][block_df['core']['Block2020'] == '410079502001025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gqtype\n",
       "0.0    16502\n",
       "1.0     1031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the variable gqtype\n",
    "hui_race_df['gqtype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vacancy\n",
       "5.0    4128\n",
       "7.0     499\n",
       "1.0     451\n",
       "3.0     222\n",
       "2.0     105\n",
       "4.0      79\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# describe the variable vacancy\n",
    "hui_race_df['vacancy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_705e2 caption {\n",
       "  text-align: center;\n",
       "  caption-side: top;\n",
       "  font-size: 150%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_705e2\">\n",
       "  <caption>Table. Total Households by Vacancy Type, Clatsop County, OR, 2020.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >All</th>\n",
       "      <th id=\"T_705e2_level0_col0\" class=\"col_heading level0 col0\" >All (%)</th>\n",
       "      <th id=\"T_705e2_level0_col1\" class=\"col_heading level0 col1\" >Total Households (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Vacancy Type</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row0\" class=\"row_heading level0 row0\" >1 For Rent</th>\n",
       "      <td id=\"T_705e2_row0_col0\" class=\"data row0 col0\" >451\t (8.2%)</td>\n",
       "      <td id=\"T_705e2_row0_col1\" class=\"data row0 col1\" >451\t (8.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row1\" class=\"row_heading level0 row1\" >2 Rented, not occupied</th>\n",
       "      <td id=\"T_705e2_row1_col0\" class=\"data row1 col0\" >105\t (1.9%)</td>\n",
       "      <td id=\"T_705e2_row1_col1\" class=\"data row1 col1\" >105\t (1.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row2\" class=\"row_heading level0 row2\" >3 For sale only</th>\n",
       "      <td id=\"T_705e2_row2_col0\" class=\"data row2 col0\" >222\t (4.0%)</td>\n",
       "      <td id=\"T_705e2_row2_col1\" class=\"data row2 col1\" >222\t (4.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row3\" class=\"row_heading level0 row3\" >4 Sold, not occupied</th>\n",
       "      <td id=\"T_705e2_row3_col0\" class=\"data row3 col0\" >79\t (1.4%)</td>\n",
       "      <td id=\"T_705e2_row3_col1\" class=\"data row3 col1\" >79\t (1.4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row4\" class=\"row_heading level0 row4\" >5 For seasonal, recreational, or occasional use</th>\n",
       "      <td id=\"T_705e2_row4_col0\" class=\"data row4 col0\" >4,128\t (75.3%)</td>\n",
       "      <td id=\"T_705e2_row4_col1\" class=\"data row4 col1\" >4,128\t (75.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row5\" class=\"row_heading level0 row5\" >7 Other vacant</th>\n",
       "      <td id=\"T_705e2_row5_col0\" class=\"data row5 col0\" >499\t (9.1%)</td>\n",
       "      <td id=\"T_705e2_row5_col1\" class=\"data row5 col1\" >499\t (9.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_705e2_level0_row6\" class=\"row_heading level0 row6\" >Total</th>\n",
       "      <td id=\"T_705e2_row6_col0\" class=\"data row6 col0\" >5,484\t (100.0%)</td>\n",
       "      <td id=\"T_705e2_row6_col1\" class=\"data row6 col1\" >5,484\t (100.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17d134a2f20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_race_df = PopResultsTable.add_vacancy_to_pop_df(hui_race_df)\n",
    "\n",
    "PopResultsTable.pop_results_table(\n",
    "                  input_df = hui_race_df, \n",
    "                  who = \"Total Households\", \n",
    "                  what = \"by Vacancy Type\",\n",
    "                  where = countyname,\n",
    "                  when = \"2020\",\n",
    "                  row_index = 'Vacancy Type',\n",
    "                  col_index = 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Population by Race and Ethnicity:\n",
      "https://data.census.gov/cedsci/table?g=050XX00US41007&tid=DECENNIALDHC2020.P5\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Population by Race and Ethnicity:\")\n",
    "print(f\"https://data.census.gov/cedsci/table?g=050XX00US{countyfips}&tid=DECENNIALDHC2020.P5\")\n",
    "\n",
    "print(\"Total Vacancy Status:\")\n",
    "print(f\"https://data.census.gov/cedsci/table?g=050XX00US{countyfips}&tid=DECENNIALDHC2020.H5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "IN-CORE_1dv1_Lumberton_CleanLODESdata_2021-05-06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyncoda20240619",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
